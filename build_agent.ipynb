{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from dataset import CIFAR10Dataset\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Classifier parameters.\n",
    "CLASSIFIER_NUMBER_OF_CLASSES = 10\n",
    "CLASSIFIER_NUMBER_OF_EPOCHS = 50\n",
    "CLASSIFIER_LEARNING_RATE = 0.01\n",
    "CLASSIFIER_BATCH_SIZE = 64\n",
    "\n",
    "# Parameters for both agents.\n",
    "\n",
    "REPLAY_BUFFER_SIZE = 5e4\n",
    "PRIOROTIZED_REPLAY_EXPONENT = 3\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-3\n",
    "TARGET_COPY_FACTOR = 0.01\n",
    "BIAS_INITIALIZATION = 0\n",
    "\n",
    "# BatchAgent's parameters.\n",
    "\n",
    "DIRNAME = './batch_agent/' # The resulting batch_agent of this experiment will be written in a file.\n",
    "\n",
    "WARM_START_EPISODES_BATCH_AGENT = 50\n",
    "NN_UPDATES_PER_EPOCHS_BATCH_AGENT = 50\n",
    "\n",
    "TRAINING_EPOCHS_BATCH_AGENT = 50\n",
    "TRAINING_EPISODES_PER_EPOCH_BATCH_AGENT = 5\n",
    "\n",
    "TESTING_EPISODES = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Delete following directories if they exist.\n",
    "for directory in [cwd+'/__pycache__', cwd+'/wandb', cwd+'/batch_agent', cwd+'/libact', cwd+'/AL_results', cwd+'/checkpoints', cwd+'/summaries', cwd+'/data', cwd+'/data_client']:\n",
    "    if os.path.exists(directory):\n",
    "        shutil.rmtree(directory, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Federated Learning: Split the CIFAR10 dataset and retrieve the subset for the first client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "def get_cifar10_splited_big_common(num_clients, trans,\n",
    "                                   root='/home/kastellosa/PycharmProjects/federated_learning/CVPR_nov_23/data',\n",
    "                                   special_client_size=0):\n",
    "    \"\"\"\n",
    "    \n",
    "    num_clients: The total number of clients to split the dataset into.\n",
    "    trans: Transformations to be applied to the images.\n",
    "    root: The root directory where the CIFAR-10 dataset is stored or should be downloaded.\n",
    "    special_client_size: The size (number of images) of the common dataset for the special client.\n",
    "    return: \n",
    "        1. Indices of  the images of the dataset for each client.\n",
    "        2. The Cifar10 dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    # Special Client Size Calculation.\n",
    "    special_indices_per_class_from_total = int(special_client_size / 10) # Calculates the number of images per class for the special client (assuming an even distribution across the 10 classes).\n",
    "    \n",
    "    # Client Number Validation.\n",
    "    # Ensures there are at least two clients.\n",
    "    if num_clients < 2:\n",
    "        raise ValueError(\"Number of clients must be at least 2.\")\n",
    "\n",
    "    # Load CIFAR-10 Dataset.\n",
    "    # Loads the CIFAR-10 training set with the specified transformations.\n",
    "    trainset = CIFAR10(root=root, train=True, download=True, transform=trans)\n",
    "\n",
    "    # Shuffle indices.\n",
    "    # Shuffles the dataset indices randomly.\n",
    "    indices = torch.randperm(len(trainset)).tolist()\n",
    "\n",
    "    # Organize indices by class.\n",
    "    # Initializes a list to hold indices for each class.\n",
    "    # Iterates over the shuffled indices,\n",
    "    # retrieves the label for each image,\n",
    "    # and appends the index to the corresponding class list.\n",
    "    class_indices = [[] for _ in range(10)]  # CIFAR10 has 10 classes.\n",
    "    for idx in indices:\n",
    "        _, label = trainset[idx]\n",
    "        class_indices[label].append(idx)\n",
    "\n",
    "    # First subset (special client).\n",
    "    # Allocate Special Client Indices.\n",
    "    # Allocates the first special_indices_per_class_from_total indices from each class to the special client.\n",
    "    # Removes these indices from the class lists.\n",
    "    special_client_indices = []\n",
    "    for class_list in class_indices:\n",
    "        special_client_indices.extend(class_list[:special_indices_per_class_from_total])\n",
    "        del class_list[:special_indices_per_class_from_total]\n",
    "\n",
    "    # Calculate the number of images per class for the remaining clients.\n",
    "    # Calculates the remaining number of images per class\n",
    "    # and the number of images per class per client\n",
    "    # (excluding the special client).\n",
    "    remaining_images_per_class = len(class_indices[0])\n",
    "    images_per_class_per_client = remaining_images_per_class // (num_clients - 1)\n",
    "\n",
    "    # Distribute remaining images among other clients.\n",
    "    # Initializes the list of client indices with the special client's indices.\n",
    "    # Iterates over the remaining clients\n",
    "    # and distributes the remaining images per class among them.\n",
    "    client_indices = [special_client_indices]  # Start with the special client.\n",
    "    for _ in range(num_clients - 1):\n",
    "        client_subset = []\n",
    "        for class_list in class_indices:\n",
    "            client_subset.extend(class_list[:images_per_class_per_client])\n",
    "            del class_list[:images_per_class_per_client]\n",
    "        client_indices.append(client_subset)\n",
    "\n",
    "    # Return.\n",
    "    # Returns the list of indices for each client and the CIFAR-10 dataset.\n",
    "    return client_indices, trainset\n",
    "\n",
    "\"\"\"\n",
    "Summary:\n",
    "\n",
    "The function get_cifar10_splited_big_common\n",
    "effectively splits the CIFAR-10 dataset into subsets for federated learning.\n",
    "It ensures one client receives a larger subset of data with an equal distribution across classes,\n",
    "while the remaining clients receive evenly distributed subsets from the remaining data.\n",
    "This can be particularly useful in scenarios where\n",
    "a common dataset needs to be shared among a subset of clients.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Define the number of clients and the size of the special client's dataset.\n",
    "num_clients = 5\n",
    "special_client_size = 10000\n",
    "root = './data'\n",
    "\n",
    "# Define the transformations to be applied to the dataset.\n",
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Call the function.\n",
    "client_indices, trainset = get_cifar10_splited_big_common(\n",
    "    num_clients=num_clients,\n",
    "    trans=trans,\n",
    "    root=root,\n",
    "    special_client_size=special_client_size\n",
    ")\n",
    "\n",
    "# Print some information about the output.\n",
    "for i, indices in enumerate(client_indices):\n",
    "    print(f\"Client {i} has {len(indices)} images.\")\n",
    "\n",
    "# Example to access the dataset for a specific client.\n",
    "client_0_data = torch.utils.data.Subset(trainset, client_indices[0])\n",
    "print(f\"First client's dataset size: {len(client_0_data)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Client's subset initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define the client.\n",
    "    - 0: First client.\n",
    "    - 1: Second client.\n",
    "    - 2: Third client.\n",
    "    - 3: Forth client.\n",
    "    - 4: Fifth client.\n",
    "\"\"\"\n",
    "\n",
    "first_client_indices = client_indices[0]\n",
    "subset_data_first_client = torch.tensor(trainset.data[first_client_indices])\n",
    "subset_labels_first_client = torch.tensor([trainset.targets[i] for i in first_client_indices])\n",
    "dataset = CIFAR10Dataset(root_dir= './data_client',length_of_client_data=len(client_0_data), data = subset_data_first_client, labels = subset_labels_first_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Warm-start data are {}.\".format(len(dataset.warm_start_data)))\n",
    "print(\"State data are {}.\".format(len(dataset.state_data)))\n",
    "print(\"Agent data are {}.\".format(len(dataset.agent_data)))\n",
    "print(\"Test data are {}.\".format(len(dataset.test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the FL round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the classifier based on the 'round'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model.\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.resnet18 = models.resnet18(pretrained=True)\n",
    "        for param in self.resnet18.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Modify the layers to handle smaller input sizes\n",
    "        self.resnet18.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.resnet18.maxpool = nn.Identity()  # Remove the max pooling layer\n",
    "        \n",
    "        num_ftrs = self.resnet18.fc.in_features\n",
    "        self.resnet18.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 3, 32, 32)\n",
    "        return self.resnet18(x)\n",
    "\n",
    "# Initialize the model and device.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "classifier = CNNClassifier()\n",
    "classifier.to(device)\n",
    "\n",
    "# If we have already run the first round of epochs, load the FL weights for the classifier.\n",
    "if round!=1:\n",
    "    classifier.load_state_dict(torch.load('classifier_weights.pth'))\n",
    "\n",
    "# Define the loss function and optimizer.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(classifier.parameters(), lr=0.01)\n",
    "\n",
    "torch.save(classifier.state_dict(), 'classifier_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_PRECISION = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the Environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batch_envs import LalEnvFirstAccuracy\n",
    "batch_env = LalEnvFirstAccuracy(dataset, classifier, epochs=CLASSIFIER_NUMBER_OF_EPOCHS, classifier_batch_size=CLASSIFIER_BATCH_SIZE, target_precision=TARGET_PRECISION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the Replay Buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batch_helpers import ReplayBuffer\n",
    "replay_buffer = ReplayBuffer(buffer_size=REPLAY_BUFFER_SIZE, prior_exp=PRIOROTIZED_REPLAY_EXPONENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()  # Clear unused memory after each episode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warm-Start episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARM-START EPISODES.\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the variables.\n",
    "episode_durations = []\n",
    "episode_scores = []\n",
    "episode_number = 1\n",
    "episode_losses = []\n",
    "episode_precisions = []\n",
    "batches = []\n",
    "\n",
    "# Warm start procedure.\n",
    "for _ in range(WARM_START_EPISODES_BATCH_AGENT):\n",
    "    print(\"Episode {}.\".format(episode_number))\n",
    "    # Reset the environment to start a new episode.\n",
    "    # print(\"- Reset.\")\n",
    "    state, next_action, indicies_unknown, reward = batch_env.reset(code_state=\"Warm-Start\", target_precision=TARGET_PRECISION, target_budget=1.0)\n",
    "    done = False\n",
    "    episode_duration = CLASSIFIER_NUMBER_OF_CLASSES\n",
    "\n",
    "    # Before we reach a terminal state, make steps.\n",
    "    while not done:\n",
    "        # Choose a random action.\n",
    "        # print(\"-- Number of actions left: {}.\".format(batch_env.n_actions))\n",
    "        if batch_env.n_actions==1:\n",
    "            batch = batch_env.n_actions\n",
    "        else:\n",
    "            batch = torch.randint(1, batch_env.n_actions + 1, (1,)).item()\n",
    "        # print(\"-- Batch: {}.\".format(batch))\n",
    "        batches.append(batch)\n",
    "\n",
    "        # Get the numbers from 0 to n_actions.\n",
    "        input_numbers = range(0, batch_env.n_actions)\n",
    "\n",
    "        # Non-repeating using sample() function.\n",
    "        batch_actions_indices = torch.tensor(np.random.choice(input_numbers, batch, replace=False))\n",
    "        # print(\"batch_actions_indices\", batch_actions_indices)\n",
    "        action = batch\n",
    "        # print(\"- Step.\")\n",
    "        next_state, next_action, indicies_unknown, reward, done = batch_env.step(batch_actions_indices)\n",
    "\n",
    "        if next_action == []:\n",
    "            next_action.append(np.array([0]))\n",
    "\n",
    "        # Store the transition in the replay buffer.\n",
    "        replay_buffer.store_transition(state, action, reward, next_state, next_action, done)\n",
    "\n",
    "        # Get ready for the next step.\n",
    "        state = next_state\n",
    "        episode_duration += batch\n",
    "\n",
    "    # Calculate the final accuracy and precision of the episode.\n",
    "    episode_final_acc = batch_env.return_episode_qualities()     \n",
    "    episode_scores.append(episode_final_acc[-1])\n",
    "    episode_final_precision = batch_env.return_episode_precisions()     \n",
    "    episode_precisions.append(episode_final_precision[-1])    \n",
    "    episode_durations.append(episode_duration)  \n",
    "    episode_number += 1\n",
    "    \n",
    "    torch.cuda.empty_cache()  # Clear unused memory after each episode.\n",
    "\n",
    "# Compute the average episode duration of episodes generated during the warm start procedure.\n",
    "av_episode_duration = np.mean(episode_durations)\n",
    "BIAS_INITIALIZATION = - av_episode_duration / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define target precision and target budget based on the Warm-Start episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Convert the list to a PyTorch tensor.\n",
    "episode_precisions = torch.tensor(episode_precisions)\n",
    "max_precision = torch.max(episode_precisions)\n",
    "\n",
    "warm_start_batches = []\n",
    "i=0\n",
    "for precision in episode_precisions:\n",
    "    if precision >= max(episode_precisions):\n",
    "        warm_start_batches.append(episode_durations[i])\n",
    "    i+=1\n",
    "TARGET_BUDGET = min(warm_start_batches)/(len(dataset.warm_start_data))\n",
    "print(\"Target budget is {}.\".format(TARGET_BUDGET))\n",
    "TARGET_PRECISION = max(episode_precisions)\n",
    "print(\"Target precision is {}.\".format(TARGET_PRECISION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the DQN based on the 'round'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batch_dqn import DQN\n",
    "batch_agent = DQN(\n",
    "            observation_length=len(dataset.state_data),\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            target_copy_factor=TARGET_COPY_FACTOR,\n",
    "            bias_average=BIAS_INITIALIZATION,\n",
    "            round = round\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent's first training using the Replay Buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for update in range(NN_UPDATES_PER_EPOCHS_BATCH_AGENT):\n",
    "    print(\"Update:\", update+1)\n",
    "    minibatch = replay_buffer.sample_minibatch(BATCH_SIZE)\n",
    "    td_error = batch_agent.train(minibatch)\n",
    "    replay_buffer.update_td_errors(td_error, minibatch.indices)\n",
    "    torch.cuda.empty_cache()  # Clear unused memory after each update."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent's training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH-AGENT TRAINING.\n",
    "\n",
    "# Initialize the agent.\n",
    "agent_epoch_durations = []\n",
    "agent_epoch_scores = []\n",
    "agent_epoch_precisions = []\n",
    "\n",
    "for epoch in range(TRAINING_EPOCHS_BATCH_AGENT):\n",
    "    print(\"Training epoch {}.\".format(epoch+1))\n",
    "\n",
    "    # Simulate training episodes.\n",
    "    agent_episode_durations = []\n",
    "    agent_episode_scores = []\n",
    "    agent_episode_precisions = []\n",
    "\n",
    "    for training_episode in range(TRAINING_EPISODES_PER_EPOCH_BATCH_AGENT):\n",
    "\n",
    "        print(\"- Training episode {}.\".format(training_episode+1))\n",
    "\n",
    "        # Reset the environment to start a new episode.\n",
    "        print(\"- Reset.\")\n",
    "        state, action_batch, action_unlabeled_data, reward = batch_env.reset(code_state=\"Agent\", target_precision=TARGET_PRECISION, target_budget=TARGET_BUDGET)\n",
    "        done = False\n",
    "        episode_duration = CLASSIFIER_NUMBER_OF_CLASSES\n",
    "        first_batch = True\n",
    "\n",
    "        # Run an episode.\n",
    "        while not done:\n",
    "            if first_batch:\n",
    "                next_batch = action_batch\n",
    "                next_unlabeled_data = action_unlabeled_data\n",
    "                first_batch = False\n",
    "            else:\n",
    "                next_batch = next_action_batch_size\n",
    "                next_unlabeled_data = next_action_unlabeled_data\n",
    "\n",
    "            selected_batch, selected_indices = batch_agent.get_action(dataset=dataset, model=classifier, state=state, next_action_batch=next_batch, next_action_unlabeled_data=next_unlabeled_data)\n",
    "            print(\"- Step.\")\n",
    "            next_state, next_action_batch_size, next_action_unlabeled_data, reward, done = batch_env.step(selected_indices)\n",
    "            if next_action_batch_size==[]:\n",
    "                next_action_batch_size.append(np.array([0]))\n",
    "\n",
    "            print(\"- Buffer.\")\n",
    "            replay_buffer.store_transition(state, selected_batch, reward, next_state, next_action_batch_size, done)\n",
    "        \n",
    "            # Change the state of the environment.\n",
    "            state = torch.tensor(next_state, dtype=torch.float32).to(device)\n",
    "            episode_duration += selected_batch\n",
    "\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        agent_episode_final_acc = batch_env.return_episode_qualities()\n",
    "        agent_episode_scores.append(agent_episode_final_acc[-1])\n",
    "        agent_episode_final_precision = batch_env.return_episode_precisions()\n",
    "        agent_episode_precisions.append(agent_episode_final_precision[-1])\n",
    "        agent_episode_durations.append(episode_duration)\n",
    "        \n",
    "    maximum_epoch_precision = max(agent_episode_precisions)\n",
    "    minimum_batches_for_the_maximum_epoch_precision = []\n",
    "    accuracy_for_the_maximum_epoch_precision = []\n",
    "    for i in range(len(agent_episode_precisions)):\n",
    "        if agent_episode_precisions[i] == maximum_epoch_precision:\n",
    "            minimum_batches_for_the_maximum_epoch_precision.append(agent_episode_durations[i])\n",
    "            accuracy_for_the_maximum_epoch_precision.append(agent_episode_scores[i])\n",
    "    agent_epoch_precisions.append(maximum_epoch_precision)\n",
    "    agent_epoch_scores.append(accuracy_for_the_maximum_epoch_precision)\n",
    "    agent_epoch_durations.append(min(minimum_batches_for_the_maximum_epoch_precision))\n",
    "\n",
    "    torch.cuda.empty_cache()  # Clear unused memory after each episode.\n",
    "\n",
    "    # NEURAL NETWORK UPDATES.\n",
    "    for update in range(NN_UPDATES_PER_EPOCHS_BATCH_AGENT):\n",
    "        minibatch = replay_buffer.sample_minibatch(BATCH_SIZE)\n",
    "        td_error = batch_agent.train(minibatch)\n",
    "        replay_buffer.update_td_errors(td_error, minibatch.indices)\n",
    "        torch.cuda.empty_cache()  # Clear unused memory after each update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save models' weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save classifier's weights.\n",
    "torch.save(classifier.state_dict(), 'classifier_weights.pth')\n",
    "\n",
    "# Save DQN's weights.\n",
    "batch_agent.save_weights('dqn_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is the end of a round."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
